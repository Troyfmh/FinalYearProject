{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log2Graphs.py\n",
    "\n",
    "\n",
    "from parse_logs import parse_log_files, parse_batch_log_files\n",
    "from make_graphs import plot_training_errors, plot_comparison_errors\n",
    "\n",
    "def log2graphs(log_file, tr_label, te_label, max_epoch=None, show=True, save=True):\n",
    "    data = parse_log_files(log_file)\n",
    "    plot_training_errors(data, tr_label, te_label, max_epoch=max_epoch, show=show, save=save)\n",
    "\n",
    "def compare_log2graphs(log_files_path, graph_label, te_label, max_epoch=100, show=True, save=True, log_y=True, log_x=False):\n",
    "    data_tag, data_list = parse_batch_log_files(log_files_path)\n",
    "    plot_comparison_errors(data_tag, data_list, graph_label, te_label, max_epoch=max_epoch, show=show, save=save, log_y=log_y, log_x=log_x)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #log2graphs(\"/Users/bd20841/code/IMP2_make_graphs/logs/new_logs/300_dt5ab_F_ga2_iter_log.txt\", tr_label=\"DT5AB_F_ga2\", te_label=\"DT4_F_containing\")\n",
    "    compare_log2graphs(\"/Users/bd20841/code/IMP2_make_graphs/logs/ga_logs\", graph_label='DT5AB_gradient_accumulation', te_label='DT3', log_y=True, log_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse logs\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "def parse_log_files(log_file):\n",
    "\n",
    "    with open(log_file, 'r') as f:\n",
    "        nmr_params = []\n",
    "\n",
    "        header_line = f.readline()\n",
    "        h_block = header_line.split('|')\n",
    "        header = h_block[1:]\n",
    "        for i in range(len(header)-1):\n",
    "                    nmr_params.append(header[i].split()[1])\n",
    "\n",
    "        values = defaultdict(list)\n",
    "\n",
    "        for idx, line in enumerate(f):\n",
    "            for i in range(len(nmr_params)):\n",
    "                main_block = line.split('|')\n",
    "                val_block = main_block[1:]\n",
    "                values[nmr_params[i]].append(float(val_block[i].split()[1]))\n",
    "    return values\n",
    "\n",
    "def parse_batch_log_files(log_files_path):\n",
    "    files = glob.glob(f\"{log_files_path}/*.txt\")\n",
    "    data_list = []\n",
    "    data_tag = []\n",
    "    for file in files:\n",
    "        tag = file.split('/')[-1].split('_')[2]\n",
    "        data = parse_log_files(file)\n",
    "        data_list.append(data)\n",
    "        data_tag.append(tag)\n",
    "\n",
    "    return data_tag, data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make graphs\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.realpath(os.path.dirname(\"TROY_PROJECT_eval_iter_log.txt\"))+'/../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_errors(data, tr_label='training_set', te_label='test_set', max_epoch=None, show=True, save=True):\n",
    "    for key, values in data.items():\n",
    "        epochs = []\n",
    "        errors = []\n",
    "        for i, error in enumerate(values):\n",
    "            epochs.append(i)\n",
    "            errors.append(error)\n",
    "            if i == max_epoch:\n",
    "                break\n",
    "\n",
    "        plt.plot(epochs, errors, label=key)\n",
    "        plt.title(f'{tr_label} errors for {key} prediction against {te_label}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss (MAE)')\n",
    "        plt.legend()\n",
    "        fig = plt.gcf()\n",
    "        if show:\n",
    "            plt.show()\n",
    "        if save:\n",
    "            if not os.path.exists(f'graphs/{tr_label}'):\n",
    "                os.makedirs(f'graphs/{tr_label}')\n",
    "            fig.savefig(f'graphs/{tr_label}/{tr_label}_{key}_training_error.png', format='png')\n",
    "\n",
    "def plot_comparison_errors(data_tag, data_list, tr_label='training_set', te_label='test_set', max_epoch=None, show=True, save=True, log_y=False, log_x=False):\n",
    "\n",
    "    for key in data_list[0].keys():\n",
    "        plt.clf()\n",
    "        for tag, data in zip(data_tag, data_list):\n",
    "            epochs = []\n",
    "            errors = []\n",
    "            for i, error in enumerate(data[key]):\n",
    "                epochs.append(i)\n",
    "                errors.append(error)\n",
    "                if i == max_epoch:\n",
    "                    break\n",
    "\n",
    "            plt.plot(epochs, errors, label=tag)\n",
    "        plt.title(f'{tr_label} errors for {key} prediction against {te_label}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss (MAE)')\n",
    "        if log_y:\n",
    "            plt.yscale('log')\n",
    "        if log_x:\n",
    "            plt.xscale('log')\n",
    "        plt.legend()\n",
    "        fig = plt.gcf()\n",
    "        if show:\n",
    "            plt.show()\n",
    "        if save:\n",
    "            if not os.path.exists(f'graphs/{tr_label}'):\n",
    "                os.makedirs(f'graphs/{tr_label}')\n",
    "            fig.savefig(f'graphs/{tr_label}/{tr_label}_{key}_training_error.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
